[Epoch 1] LR=0.0001, BS=64, train_loss=0.9906, val_loss=1.3004, val_acc=0.4075
[Epoch 2] LR=0.0001, BS=64, train_loss=0.6451, val_loss=1.0053, val_acc=0.5900
[Epoch 3] LR=0.0001, BS=64, train_loss=0.3893, val_loss=1.1781, val_acc=0.6000
[Epoch 4] LR=0.0001, BS=64, train_loss=0.2677, val_loss=1.2138, val_acc=0.6550
[Epoch 5] LR=0.0001, BS=64, train_loss=0.1898, val_loss=1.3550, val_acc=0.6000
最终对齐向量加简单mlp融合
[Epoch 1] LR=0.0001, BS=64, train_loss=0.9079, val_loss=1.2489, val_acc=0.5275
[Epoch 2] LR=0.0001, BS=64, train_loss=0.5142, val_loss=1.0210, val_acc=0.6375
[Epoch 3] LR=0.0001, BS=64, train_loss=0.2758, val_loss=1.0368, val_acc=0.6650
[Epoch 4] LR=0.0001, BS=64, train_loss=0.1657, val_loss=1.2953, val_acc=0.6525
[Epoch 5] LR=0.0001, BS=64, train_loss=0.1688, val_loss=1.2972, val_acc=0.6175
最终对齐向量加简单mlp融合
[Epoch 1] LR=1e-05, BS=64, train_loss=0.8828, val_loss=0.7654, val_acc=0.7075
[Epoch 2] LR=1e-05, BS=64, train_loss=0.4084, val_loss=0.6572, val_acc=0.7350
[Epoch 3] LR=1e-05, BS=64, train_loss=0.1993, val_loss=0.6546, val_acc=0.7725
[Epoch 4] LR=1e-05, BS=64, train_loss=0.1085, val_loss=0.7832, val_acc=0.7225
[Epoch 5] LR=1e-05, BS=64, train_loss=0.0731, val_loss=0.7485, val_acc=0.7625
深度互注意力：
[Epoch 1] LR=1e-05, BS=64, train_loss=0.8042, val_loss=0.8067, val_acc=0.6375
[Epoch 3] LR=1e-05, BS=64, train_loss=0.1439, val_loss=0.6842, val_acc=0.7425
[Epoch 4] LR=1e-05, BS=64, train_loss=0.1012, val_loss=0.6999, val_acc=0.7575
[Epoch 5] LR=1e-05, BS=64, train_loss=0.0696, val_loss=0.9202, val_acc=0.7275
深度互注意力：
[Epoch 1] LR=3e-06, BS=64, train_loss=1.0047, val_loss=0.9241, val_acc=0.5825
[Epoch 2] LR=3e-06, BS=64, train_loss=0.6506, val_loss=0.6950, val_acc=0.7400
[Epoch 3] LR=3e-06, BS=64, train_loss=0.3201, val_loss=0.6619, val_acc=0.7750
[Epoch 4] LR=3e-06, BS=64, train_loss=0.1908, val_loss=0.7060, val_acc=0.7525
[Epoch 5] LR=3e-06, BS=64, train_loss=0.1108, val_loss=0.6762, val_acc=0.7550
深度互注意力：
[Epoch 1] LR=1e-06, BS=64, train_loss=1.0677, val_loss=1.0534, val_acc=0.4675
[Epoch 2] LR=1e-06, BS=64, train_loss=0.9948, val_loss=1.0269, val_acc=0.4750
[Epoch 3] LR=1e-06, BS=64, train_loss=0.8886, val_loss=0.9230, val_acc=0.5350
[Epoch 4] LR=1e-06, BS=64, train_loss=0.7157, val_loss=0.8099, val_acc=0.6200
[Epoch 5] LR=1e-06, BS=64, train_loss=0.4919, val_loss=0.7014, val_acc=0.7200
[Epoch 6] LR=1e-06, BS=64, train_loss=0.3248, val_loss=0.7104, val_acc=0.7375
[Epoch 7] LR=1e-06, BS=64, train_loss=0.2281, val_loss=0.7117, val_acc=0.7375
[Epoch 8] LR=1e-06, BS=64, train_loss=0.1520, val_loss=0.7136, val_acc=0.7750
浅层互注意力：
[Epoch 1] LR=3e-06, BS=64, train_loss=1.0738, val_loss=1.0505, val_acc=0.5975
[Epoch 2] LR=3e-06, BS=64, train_loss=0.9672, val_loss=0.9576, val_acc=0.6150
[Epoch 3] LR=3e-06, BS=64, train_loss=0.7457, val_loss=0.8412, val_acc=0.7275
[Epoch 4] LR=3e-06, BS=64, train_loss=0.5029, val_loss=0.7359, val_acc=0.7650
[Epoch 5] LR=3e-06, BS=64, train_loss=0.3200, val_loss=0.7067, val_acc=0.7625
[Epoch 6] LR=3e-06, BS=64, train_loss=0.1917, val_loss=0.8000, val_acc=0.7075
[Epoch 7] LR=3e-06, BS=64, train_loss=0.1207, val_loss=0.7951, val_acc=0.7175
[Epoch 8] LR=3e-06, BS=64, train_loss=0.0920, val_loss=0.8215, val_acc=0.7425
最终对齐向量加可学习权重加简单mlp融合：
[Epoch 1] LR=3e-06, BS=64, train_loss=1.0360, val_loss=0.9874, val_acc=0.6725
[Epoch 2] LR=3e-06, BS=64, train_loss=0.8470, val_loss=0.8256, val_acc=0.7250
[Epoch 3] LR=3e-06, BS=64, train_loss=0.5579, val_loss=0.6566, val_acc=0.7525
[Epoch 4] LR=3e-06, BS=64, train_loss=0.3058, val_loss=0.6792, val_acc=0.7100
[Epoch 5] LR=3e-06, BS=64, train_loss=0.1859, val_loss=0.6219, val_acc=0.7525
[Epoch 6] LR=3e-06, BS=64, train_loss=0.1140, val_loss=0.6677, val_acc=0.7400
[Epoch 7] LR=3e-06, BS=64, train_loss=0.0834, val_loss=0.5891, val_acc=0.7550
[Epoch 8] LR=3e-06, BS=64, train_loss=0.0561, val_loss=0.6222, val_acc=0.7625
最终对齐向量加对比损失加简单mlp融合：
[Epoch 1] LR=3e-06, BS=64, train_loss=1.0360, val_loss=0.9871, val_acc=0.6750
[Epoch 2] LR=3e-06, BS=64, train_loss=0.8470, val_loss=0.8278, val_acc=0.7250
[Epoch 3] LR=3e-06, BS=64, train_loss=0.5582, val_loss=0.6510, val_acc=0.7600
[Epoch 4] LR=3e-06, BS=64, train_loss=0.3035, val_loss=0.6570, val_acc=0.7450
[Epoch 5] LR=3e-06, BS=64, train_loss=0.1806, val_loss=0.6630, val_acc=0.7350
[Epoch 6] LR=3e-06, BS=64, train_loss=0.1162, val_loss=0.6765, val_acc=0.7275
[Epoch 7] LR=3e-06, BS=64, train_loss=0.0822, val_loss=0.6019, val_acc=0.7450
[Epoch 1] LR=3e-06, BS=64, train_loss=1.0576, val_loss=1.0067, val_acc=0.6375
[Epoch 2] LR=3e-06, BS=64, train_loss=0.8261, val_loss=0.7704, val_acc=0.7000
[Epoch 3] LR=3e-06, BS=64, train_loss=0.4631, val_loss=0.6629, val_acc=0.7200
[Epoch 4] LR=3e-06, BS=64, train_loss=0.2637, val_loss=0.6298, val_acc=0.7500
[Epoch 5] LR=3e-06, BS=64, train_loss=0.1605, val_loss=0.6809, val_acc=0.7525
[Epoch 1] LR=3e-06, BS=64, train_loss=1.0763, val_loss=1.0433, val_acc=0.5950
[Epoch 2] LR=3e-06, BS=64, train_loss=0.9099, val_loss=0.8451, val_acc=0.6800
[Epoch 3] LR=3e-06, BS=64, train_loss=0.5685, val_loss=0.7383, val_acc=0.6925
[Epoch 4] LR=3e-06, BS=64, train_loss=0.3419, val_loss=0.6888, val_acc=0.7425
[Epoch 5] LR=3e-06, BS=64, train_loss=0.2125, val_loss=0.7360, val_acc=0.7500
[Epoch 6] LR=3e-06, BS=64, train_loss=0.1417, val_loss=0.7789, val_acc=0.7400
[Epoch 7] LR=3e-06, BS=64, train_loss=0.1026, val_loss=0.8094, val_acc=0.7625
[Epoch 1] LR=3e-06, BS=64, train_loss=1.0673, val_loss=1.0012, val_acc=0.6000
[Epoch 2] LR=3e-06, BS=64, train_loss=0.8087, val_loss=0.7580, val_acc=0.7050
[Epoch 3] LR=3e-06, BS=64, train_loss=0.4669, val_loss=0.5960, val_acc=0.7850
[Epoch 4] LR=3e-06, BS=64, train_loss=0.2562, val_loss=0.6401, val_acc=0.7550
[Epoch 5] LR=3e-06, BS=64, train_loss=0.1794, val_loss=0.6364, val_acc=0.7825
[Epoch 6] LR=3e-06, BS=64, train_loss=0.1146, val_loss=0.6928, val_acc=0.7700
[Epoch 7] LR=3e-06, BS=64, train_loss=0.0979, val_loss=0.7285, val_acc=0.7800
[Epoch 8] LR=3e-06, BS=64, train_loss=0.0854, val_loss=0.7054, val_acc=0.7850
[Epoch 1] LR=3e-06, BS=64, train_loss=1.0158, val_loss=0.8994, val_acc=0.6475
[Epoch 2] LR=3e-06, BS=64, train_loss=0.6068, val_loss=0.6484, val_acc=0.7450
[Epoch 3] LR=3e-06, BS=64, train_loss=0.2843, val_loss=0.6203, val_acc=0.7575
[Epoch 4] LR=3e-06, BS=64, train_loss=0.1781, val_loss=0.6552, val_acc=0.7700
[Epoch 5] LR=3e-06, BS=64, train_loss=0.1128, val_loss=0.7457, val_acc=0.7675
[Epoch 6] LR=3e-06, BS=64, train_loss=0.0844, val_loss=0.7066, val_acc=0.7775
[Epoch 7] LR=3e-06, BS=64, train_loss=0.0550, val_loss=0.7495, val_acc=0.7825
[Epoch 8] LR=3e-06, BS=64, train_loss=0.0344, val_loss=0.8282, val_acc=0.7700
[Epoch 1] LR=3e-06, BS=64, train_loss=1.0083, val_loss=0.8833, val_acc=0.5500
[Epoch 2] LR=3e-06, BS=64, train_loss=0.5988, val_loss=0.6423, val_acc=0.7525
[Epoch 3] LR=3e-06, BS=64, train_loss=0.3305, val_loss=0.6812, val_acc=0.7400
[Epoch 4] LR=3e-06, BS=64, train_loss=0.1970, val_loss=0.7196, val_acc=0.7325
[Epoch 5] LR=3e-06, BS=64, train_loss=0.1346, val_loss=0.6987, val_acc=0.7775
[Epoch 6] LR=3e-06, BS=64, train_loss=0.1042, val_loss=0.7438, val_acc=0.7675
[Epoch 7] LR=3e-06, BS=64, train_loss=0.0702, val_loss=0.7279, val_acc=0.7700
[Epoch 8] LR=3e-06, BS=64, train_loss=0.0717, val_loss=1.0933, val_acc=0.7050
[Epoch 1] LR=1e-05, BS=64, train_loss=0.9059, val_loss=0.7086, val_acc=0.6925
[Epoch 2] LR=1e-05, BS=64, train_loss=0.4678, val_loss=0.5974, val_acc=0.7675
[Epoch 3] LR=1e-05, BS=64, train_loss=0.2622, val_loss=0.7277, val_acc=0.7525
[Epoch 4] LR=1e-05, BS=64, train_loss=0.1814, val_loss=0.8500, val_acc=0.7275
[Epoch 5] LR=1e-05, BS=64, train_loss=0.1433, val_loss=0.8225, val_acc=0.7475
[Epoch 1] LR=3e-06, BS=32, train_loss=1.0240, val_loss=0.9020, val_acc=0.6300
[Epoch 2] LR=3e-06, BS=32, train_loss=0.5888, val_loss=0.6151, val_acc=0.7600
[Epoch 3] LR=3e-06, BS=32, train_loss=0.3188, val_loss=0.7683, val_acc=0.6925
[Epoch 4] LR=3e-06, BS=32, train_loss=0.1815, val_loss=0.8018, val_acc=0.7475
[Epoch 1] LR=3e-06, BS=64, train_loss=1.0673, val_loss=1.0012, val_acc=0.6000
[Epoch 2] LR=3e-06, BS=64, train_loss=0.8087, val_loss=0.7580, val_acc=0.7050
[Epoch 3] LR=3e-06, BS=64, train_loss=0.4669, val_loss=0.5960, val_acc=0.7850
[Epoch 1] LR=3e-06, BS=64, train_loss=0.9584, val_loss=0.6919, val_acc=0.7250
[Epoch 2] LR=3e-06, BS=64, train_loss=0.3989, val_loss=0.6285, val_acc=0.7650
[Epoch 3] LR=3e-06, BS=64, train_loss=0.1571, val_loss=0.7346, val_acc=0.7625
[Epoch 4] LR=3e-06, BS=64, train_loss=0.0965, val_loss=0.8184, val_acc=0.7725
[Epoch 1] LR=3e-06, BS=64, train_loss=1.0673, val_loss=1.0012, val_acc=0.6000
[Epoch 1] LR=3e-06, BS=64, train_loss=1.0673, val_loss=1.0012, val_acc=0.6000
[Epoch 1] LR=3e-06, BS=64, train_loss=1.0673, val_loss=1.0012, val_acc=0.6000
[Epoch 2] LR=3e-06, BS=64, train_loss=0.8087, val_loss=0.7580, val_acc=0.7050
[Epoch 3] LR=3e-06, BS=64, train_loss=0.4669, val_loss=0.5960, val_acc=0.7850
[Epoch 1] LR=3e-06, BS=64, train_loss=1.0613, val_loss=0.9565, val_acc=0.7750
[Epoch 2] LR=3e-06, BS=64, train_loss=0.8028, val_loss=0.5992, val_acc=0.8000
[Epoch 3] LR=3e-06, BS=64, train_loss=0.4484, val_loss=0.5432, val_acc=0.7750
[Epoch 1] LR=3e-06, BS=64, train_loss=1.0613, val_loss=0.9565, val_acc=0.7750
[Epoch 2] LR=3e-06, BS=64, train_loss=0.8028, val_loss=0.5992, val_acc=0.8000
[Epoch 3] LR=3e-06, BS=64, train_loss=0.4484, val_loss=0.5432, val_acc=0.7750
仅图像：
[Epoch 1] LR=3e-06, BS=64, train_loss=1.0884, val_loss=1.0599, val_acc=0.4725
[Epoch 2] LR=3e-06, BS=64, train_loss=0.8911, val_loss=0.8671, val_acc=0.6325
[Epoch 3] LR=3e-06, BS=64, train_loss=0.6070, val_loss=0.7609, val_acc=0.6775
[Epoch 4] LR=3e-06, BS=64, train_loss=0.3835, val_loss=0.6857, val_acc=0.7425
[Epoch 5] LR=3e-06, BS=64, train_loss=0.2740, val_loss=0.7605, val_acc=0.7175
[Epoch 6] LR=3e-06, BS=64, train_loss=0.1943, val_loss=0.8508, val_acc=0.7250
[Epoch 7] LR=3e-06, BS=64, train_loss=0.1398, val_loss=0.8820, val_acc=0.7050
[Epoch 8] LR=3e-06, BS=64, train_loss=0.1176, val_loss=0.9517, val_acc=0.7025
[Epoch 9] LR=3e-06, BS=64, train_loss=0.0918, val_loss=0.9516, val_acc=0.7000
[Epoch 10] LR=3e-06, BS=64, train_loss=0.0700, val_loss=0.9756, val_acc=0.7175
仅文本：
[Epoch 1] LR=3e-06, BS=64, train_loss=1.0952, val_loss=1.0745, val_acc=0.3200
[Epoch 2] LR=3e-06, BS=64, train_loss=0.9996, val_loss=0.9288, val_acc=0.5825
[Epoch 3] LR=3e-06, BS=64, train_loss=0.6771, val_loss=0.7521, val_acc=0.6875
[Epoch 4] LR=3e-06, BS=64, train_loss=0.4073, val_loss=0.7841, val_acc=0.7050
[Epoch 5] LR=3e-06, BS=64, train_loss=0.2796, val_loss=0.8993, val_acc=0.6825
[Epoch 6] LR=3e-06, BS=64, train_loss=0.1958, val_loss=0.8710, val_acc=0.7150
[Epoch 7] LR=3e-06, BS=64, train_loss=0.1392, val_loss=0.9714, val_acc=0.7075
[Epoch 8] LR=3e-06, BS=64, train_loss=0.1088, val_loss=0.9985, val_acc=0.7125
[Epoch 9] LR=3e-06, BS=64, train_loss=0.1031, val_loss=1.1119, val_acc=0.7100
[Epoch 10] LR=3e-06, BS=64, train_loss=0.0927, val_loss=1.0954, val_acc=0.7225
多模态深融合：
[Epoch 1] LR=3e-06, BS=64, train_loss=1.0673, val_loss=1.0012, val_acc=0.6000
[Epoch 2] LR=3e-06, BS=64, train_loss=0.8087, val_loss=0.7580, val_acc=0.7050
[Epoch 3] LR=3e-06, BS=64, train_loss=0.4669, val_loss=0.5960, val_acc=0.7850
[Epoch 4] LR=3e-06, BS=64, train_loss=0.2562, val_loss=0.6401, val_acc=0.7550
[Epoch 5] LR=3e-06, BS=64, train_loss=0.1794, val_loss=0.6364, val_acc=0.7825
[Epoch 6] LR=3e-06, BS=64, train_loss=0.1146, val_loss=0.6928, val_acc=0.7700
[Epoch 7] LR=3e-06, BS=64, train_loss=0.0979, val_loss=0.7285, val_acc=0.7800
[Epoch 8] LR=3e-06, BS=64, train_loss=0.0854, val_loss=0.7054, val_acc=0.7850
[Epoch 9] LR=3e-06, BS=64, train_loss=0.0583, val_loss=0.7293, val_acc=0.7875
[Epoch 10] LR=3e-06, BS=64, train_loss=0.0608, val_loss=0.7990, val_acc=0.7750
多模态浅融合：
[Epoch 1] LR=3e-06, BS=64, train_loss=1.0738, val_loss=1.0505, val_acc=0.5975
[Epoch 2] LR=3e-06, BS=64, train_loss=0.9672, val_loss=0.9576, val_acc=0.6150
[Epoch 3] LR=3e-06, BS=64, train_loss=0.7457, val_loss=0.8412, val_acc=0.7275
[Epoch 4] LR=3e-06, BS=64, train_loss=0.5029, val_loss=0.7359, val_acc=0.7650
[Epoch 5] LR=3e-06, BS=64, train_loss=0.3200, val_loss=0.7067, val_acc=0.7625
[Epoch 6] LR=3e-06, BS=64, train_loss=0.1917, val_loss=0.8000, val_acc=0.7075
[Epoch 7] LR=3e-06, BS=64, train_loss=0.1207, val_loss=0.7951, val_acc=0.7175
[Epoch 8] LR=3e-06, BS=64, train_loss=0.0920, val_loss=0.8215, val_acc=0.7425
[Epoch 9] LR=3e-06, BS=64, train_loss=0.0589, val_loss=0.8449, val_acc=0.7400
[Epoch 10] LR=3e-06, BS=64, train_loss=0.0512, val_loss=0.8509, val_acc=0.7625
多模态无注意力：
[Epoch 1] LR=3e-06, BS=64, train_loss=1.0360, val_loss=0.9871, val_acc=0.6750
[Epoch 2] LR=3e-06, BS=64, train_loss=0.8470, val_loss=0.8278, val_acc=0.7250
[Epoch 3] LR=3e-06, BS=64, train_loss=0.5582, val_loss=0.6510, val_acc=0.7600
[Epoch 4] LR=3e-06, BS=64, train_loss=0.3035, val_loss=0.6570, val_acc=0.7450
[Epoch 5] LR=3e-06, BS=64, train_loss=0.1806, val_loss=0.6630, val_acc=0.7350
[Epoch 6] LR=3e-06, BS=64, train_loss=0.1162, val_loss=0.6765, val_acc=0.7275
[Epoch 7] LR=3e-06, BS=64, train_loss=0.0822, val_loss=0.6019, val_acc=0.7450
[Epoch 8] LR=3e-06, BS=64, train_loss=0.0573, val_loss=0.6455, val_acc=0.7450
[Epoch 9] LR=3e-06, BS=64, train_loss=0.0432, val_loss=0.7158, val_acc=0.7650
[Epoch 10] LR=3e-06, BS=64, train_loss=0.0444, val_loss=0.6905, val_acc=0.7375
